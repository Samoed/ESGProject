import pandas as pd
import numpy as np
from collections import defaultdict


df = pd.read_csv("paragrapghs_with_topics_banks.csv", index_col=0)
# df = pd.read_csv("../topics/paragrapghs_with_topics.csv.zip", index_col=0)
df.head()


not_nan = df[df["max_topic_exp"].notna()]
# число абзацев соотвествующих теме
reports = not_nan.groupby(["year", "company", "index", "max_topic_exp"])["paragraph"].count()
reports.head()








topics_per_report = not_nan.groupby(["year", "index"])["paragraph"].count()
topics_per_report.head()


tf = defaultdict(dict)
for (year, file_name, index, topic), row in reports.items():
    tf[(year, index)][topic] = row / topics_per_report[year][index]
tf = pd.DataFrame(tf).T





tf


idf = {}
for topic in df["max_topic_exp"].unique():
    if pd.isna(topic):
        continue
    idf[topic] = np.log(df["index"].nunique() / tf[topic].notna().sum())
idf = pd.Series(idf)


tf_idf = defaultdict(dict)
for idx, row in tf.iterrows():
    for topic in row.index:
        tf_idf[idx][topic] = row[topic] * idf[topic]


tf_idf = pd.DataFrame(tf_idf).T
tf_idf = tf_idf.fillna(0)
tf_idf.head()


tf_idf.to_csv("tf_idf.csv")


topic_words = pd.read_csv("../topic_words.csv", index_col=0)
topic_words.head()


gr = topic_words.groupby("meta")["topic"].apply(set)





from pymcdm.methods import TOPSIS


gr = (
    df.drop(
        columns=[
            "Unnamed: 0",
            "paragraph",
            "original_text",
            "cleaned_text",
            "max_topic_cos",
            "max_score_cos",
            "count_words",
            "second_max_topic_cos",
            "second_max_score_cos",
            "max_topic_exp",
            "max_score_exp",
            "second_max_topic_exp",
            "second_max_score_exp",
        ]
    )
    .groupby(["year", "company", "index"])
    .mean()
    .dropna(how="all")
)
gr.head()


topics = topic_words.groupby("meta")["topic"].apply(set)


gr.reset_index(inplace=True)
gr = gr.set_index("index")
gr.head()


def second_workflow(data: pd.DataFrame):
    matrix = data.to_numpy()
    weights = np.array([1 / matrix.shape[0]] * matrix.shape[1])
    types = np.ones(matrix.shape[1], dtype=int)
    body = TOPSIS()
    predictions = [round(preference, 2) for preference in body(matrix, weights, types)]
    return predictions


bad = ["Кибербезопасность", "Инновации", "Персонал в целом"]

for year in gr["year"].unique():
    year_data = gr[gr["year"] == year]
    for key, cur_topics in topics.items():
        tmp_topics = []
        for t in cur_topics:
            if t not in bad:
                tmp_topics.append(t)
            else:
                tmp_topics.append("!" + t)
        cur_topics = tmp_topics
        res = second_workflow(year_data[cur_topics])
        res = pd.Series(res).set_axis(year_data.index)
        gr.loc[gr["year"] == year, key] = res


gr["avg"] = (gr["env"] + gr["gov"] + gr["social"]) / 3
gr["on_letters"] = second_workflow(gr[["env", "gov", "social"]])
gr = gr.sort_values(["year", "avg"], ascending=[True, False])
gr.head()


bad = ["Кибербезопасность", "Инновации", "Персонал в целом"]

for year in gr["year"].unique():
    year_data = gr[gr["year"] == year]
    tmp_topics = []
    for t in [v for _, val in topics.items() for v in val]:
        if t not in bad:
            tmp_topics.append(t)
        else:
            tmp_topics.append("!" + t)
    cur_topics = tmp_topics
    res = second_workflow(year_data[cur_topics])
    res = pd.Series(res).set_axis(year_data.index)
    gr.loc[gr["year"] == year, "all_letters"] = res


for year in gr["year"].unique():
    gr[gr["year"] == year].to_csv(f"banks_results_{year}.csv")
gr.to_csv("banks_results.csv")


res.shape



